{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "839dfa39",
   "metadata": {},
   "source": [
    "This notebook gives some fundamentals on Bagging and Boosting methods for the star/galaxy/quasar classification.\n",
    "\n",
    "Written with ❤️ by Viviana Acquaviva for the LSST Data Science Fellowship lecture series.\n",
    "\n",
    "License: [BSD-3-clause](https://opensource.org/license/bsd-3-clause/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dc96f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict, cross_validate\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f805580",
   "metadata": {},
   "source": [
    "We follow the same steps as before to derive the final data set. Note - because we are dealing with more complex models, I am reducing the sample size to ~10,000 (feel free to change frac to 0.05 if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7087ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('star_classification.csv', sep = ',')\n",
    "\n",
    "df = data.sample(frac = 0.1, random_state = 11)\n",
    "\n",
    "df.reset_index(drop = True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f290ce8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_867897/129157639.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  seldf['u-g'] = seldf['u']-seldf['g']\n",
      "/tmp/ipykernel_867897/129157639.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  seldf['u-r'] = seldf['u']-seldf['r']\n",
      "/tmp/ipykernel_867897/129157639.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  seldf['u-i'] = seldf['u']-seldf['i']\n",
      "/tmp/ipykernel_867897/129157639.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  seldf['u-z'] = seldf['u']-seldf['z']\n",
      "/tmp/ipykernel_867897/129157639.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  seldf['g-r'] = seldf['g']-seldf['r']\n",
      "/tmp/ipykernel_867897/129157639.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  seldf['g-i'] = seldf['g']-seldf['i']\n",
      "/tmp/ipykernel_867897/129157639.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  seldf['g-z'] = seldf['g']-seldf['z']\n",
      "/tmp/ipykernel_867897/129157639.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  seldf['r-i'] = seldf['r']-seldf['i']\n",
      "/tmp/ipykernel_867897/129157639.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  seldf['r-z'] = seldf['r']-seldf['z']\n",
      "/tmp/ipykernel_867897/129157639.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  seldf['i-z'] = seldf['i']-seldf['z']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z</th>\n",
       "      <th>u-g</th>\n",
       "      <th>u-r</th>\n",
       "      <th>u-i</th>\n",
       "      <th>u-z</th>\n",
       "      <th>r-i</th>\n",
       "      <th>r-z</th>\n",
       "      <th>i-z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.29095</td>\n",
       "      <td>0.25792</td>\n",
       "      <td>1.85365</td>\n",
       "      <td>2.96112</td>\n",
       "      <td>3.27271</td>\n",
       "      <td>1.10747</td>\n",
       "      <td>1.41906</td>\n",
       "      <td>0.31159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.68413</td>\n",
       "      <td>0.08602</td>\n",
       "      <td>0.54327</td>\n",
       "      <td>0.51648</td>\n",
       "      <td>0.92852</td>\n",
       "      <td>-0.02679</td>\n",
       "      <td>0.38525</td>\n",
       "      <td>0.41204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.79408</td>\n",
       "      <td>1.17334</td>\n",
       "      <td>1.09258</td>\n",
       "      <td>0.95385</td>\n",
       "      <td>0.97952</td>\n",
       "      <td>-0.13873</td>\n",
       "      <td>-0.11306</td>\n",
       "      <td>0.02567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.32981</td>\n",
       "      <td>1.47126</td>\n",
       "      <td>2.18205</td>\n",
       "      <td>2.59721</td>\n",
       "      <td>2.84297</td>\n",
       "      <td>0.41516</td>\n",
       "      <td>0.66092</td>\n",
       "      <td>0.24576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.91509</td>\n",
       "      <td>5.87230</td>\n",
       "      <td>7.51612</td>\n",
       "      <td>8.15238</td>\n",
       "      <td>8.55422</td>\n",
       "      <td>0.63626</td>\n",
       "      <td>1.03810</td>\n",
       "      <td>0.40184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>15.83632</td>\n",
       "      <td>1.94273</td>\n",
       "      <td>3.22556</td>\n",
       "      <td>3.72978</td>\n",
       "      <td>4.05021</td>\n",
       "      <td>0.50422</td>\n",
       "      <td>0.82465</td>\n",
       "      <td>0.32043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>16.09191</td>\n",
       "      <td>1.40299</td>\n",
       "      <td>1.89845</td>\n",
       "      <td>2.06636</td>\n",
       "      <td>2.14349</td>\n",
       "      <td>0.16791</td>\n",
       "      <td>0.24504</td>\n",
       "      <td>0.07713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>13.73334</td>\n",
       "      <td>1.23197</td>\n",
       "      <td>1.78568</td>\n",
       "      <td>2.09712</td>\n",
       "      <td>2.32405</td>\n",
       "      <td>0.31144</td>\n",
       "      <td>0.53837</td>\n",
       "      <td>0.22693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>18.78040</td>\n",
       "      <td>1.74579</td>\n",
       "      <td>2.10208</td>\n",
       "      <td>2.38794</td>\n",
       "      <td>2.42846</td>\n",
       "      <td>0.28586</td>\n",
       "      <td>0.32638</td>\n",
       "      <td>0.04052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>15.63152</td>\n",
       "      <td>1.76091</td>\n",
       "      <td>2.70512</td>\n",
       "      <td>3.15967</td>\n",
       "      <td>3.49161</td>\n",
       "      <td>0.45455</td>\n",
       "      <td>0.78649</td>\n",
       "      <td>0.33194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             z      u-g      u-r      u-i      u-z      r-i      r-z      i-z\n",
       "0     19.29095  0.25792  1.85365  2.96112  3.27271  1.10747  1.41906  0.31159\n",
       "1     20.68413  0.08602  0.54327  0.51648  0.92852 -0.02679  0.38525  0.41204\n",
       "2     20.79408  1.17334  1.09258  0.95385  0.97952 -0.13873 -0.11306  0.02567\n",
       "3     16.32981  1.47126  2.18205  2.59721  2.84297  0.41516  0.66092  0.24576\n",
       "4     17.91509  5.87230  7.51612  8.15238  8.55422  0.63626  1.03810  0.40184\n",
       "...        ...      ...      ...      ...      ...      ...      ...      ...\n",
       "9995  15.83632  1.94273  3.22556  3.72978  4.05021  0.50422  0.82465  0.32043\n",
       "9996  16.09191  1.40299  1.89845  2.06636  2.14349  0.16791  0.24504  0.07713\n",
       "9997  13.73334  1.23197  1.78568  2.09712  2.32405  0.31144  0.53837  0.22693\n",
       "9998  18.78040  1.74579  2.10208  2.38794  2.42846  0.28586  0.32638  0.04052\n",
       "9999  15.63152  1.76091  2.70512  3.15967  3.49161  0.45455  0.78649  0.33194\n",
       "\n",
       "[10000 rows x 8 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seldf = df[['u','g','r','i','z']]\n",
    "\n",
    "seldf['u-g'] = seldf['u']-seldf['g']\n",
    "seldf['u-r'] = seldf['u']-seldf['r']\n",
    "seldf['u-i'] = seldf['u']-seldf['i']\n",
    "seldf['u-z'] = seldf['u']-seldf['z']\n",
    "\n",
    "seldf['g-r'] = seldf['g']-seldf['r']\n",
    "seldf['g-i'] = seldf['g']-seldf['i']\n",
    "seldf['g-z'] = seldf['g']-seldf['z']\n",
    "\n",
    "seldf['r-i'] = seldf['r']-seldf['i']\n",
    "seldf['r-z'] = seldf['r']-seldf['z']\n",
    "\n",
    "seldf['i-z'] = seldf['i']-seldf['z']\n",
    "\n",
    "\n",
    "seldf.drop(columns=['g','g-r','g-z','r','i','g-i','u'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b068a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in seldf.columns:\n",
    "    seldf = seldf[seldf[col] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f56a5e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "67000658",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder() #turns categorical into 1 ... N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "579aa561",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = le.fit_transform(df['class'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "daecf4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GALAXY', 'QSO', 'STAR'], dtype=object)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ac7be7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GALAXY': 0, 'QSO': 1, 'STAR': 2}\n"
     ]
    }
   ],
   "source": [
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "293ab90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = y[seldf.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0819e1c0",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "73505489",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1da7fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, random_state=10, shuffle= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7b1bd0",
   "metadata": {},
   "source": [
    "We can establish a benchmark, as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "20e38777",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(model, seldf, target, cv = cv, return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4b66363c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.015s, Mean train score: 1.000, Mean test score: 0.898, std: 0.008\n"
     ]
    }
   ],
   "source": [
    "print(\"Time: %.3fs, Mean train score: %.3f, Mean test score: %.3f, std: %.3f\"%(scores['score_time'].mean(), scores['train_score'].mean(), scores['test_score'].mean(), scores['test_score'].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b303d7",
   "metadata": {},
   "source": [
    "As usual, we can get a landscape of model parameters like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d32415b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4beaced",
   "metadata": {},
   "source": [
    "It may be useful to distinguish between the parameters of the decision tree, the randomization process, and the averaging process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4099d544",
   "metadata": {},
   "source": [
    "#### Tree Parameters\n",
    "\n",
    "Some useful parameters associated to a tree are:\n",
    "\n",
    "- the minimum number of instances in a leaf node; \n",
    "- the minimum number of instances required in a split node;\n",
    "- the maximum depth of tree;\n",
    "- the minimum information gain required to decide whether a split is \"worth it\".\n",
    "\n",
    "#### Randomization Parameters\n",
    "\n",
    "Here we find:\n",
    "\n",
    "-    The number of k < n features that are used in building trees (max_features);\n",
    "\n",
    "-    The re-sampling (boostrap) of the data set (T or F).\n",
    "\n",
    "#### Forest Parameters\n",
    "\n",
    "The number of trees in the forest (n_estimators) can be adjusted, with the general understanding that more trees are better, but at some point performance will plateau, so one can find the trade-off between having more trees and lower runtime.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf097a5e",
   "metadata": {},
   "source": [
    "### Optimizing hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1135f5ac",
   "metadata": {},
   "source": [
    "Finally, the cell below shows how to run a Grid Search for the parameters for some example sets; if a Grid Search is too expensive, we can also run a Randomized Search, which doesn't guarantee that we'll find the best model, but usually gets us close enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e4e9961f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=10, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=50, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=10, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=10, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=50, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=50, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=50, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=10, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=10, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=50, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=10, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=10, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=50, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=50, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=10, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=50, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=50, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=100, subsample=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=50, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=50, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=50, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=10, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=10, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=50, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=10, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=50, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=50, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=10, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=50, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=10, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=10, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=50, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params, best score: 0.9004 {'max_depth': 15, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "#Takes ~ 25 secs min for me\n",
    "\n",
    "parameters = {'min_impurity_decrease':[0.0], \\\n",
    "              'max_features':[None,8,4], 'n_estimators':[50, 100, 150,200], 'max_depth': [15,20,25]}\n",
    "\n",
    "model = GridSearchCV(RandomForestClassifier(), parameters, cv = KFold(n_splits=5, shuffle=True), \\\n",
    "                      n_jobs = -1, return_train_score=True)\n",
    "model.fit(seldf,target)\n",
    "\n",
    "print('Best params, best score:', \"{:.4f}\".format(model.best_score_), \\\n",
    "      model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dccbea",
   "metadata": {},
   "source": [
    "We can save the results in a data frame, and look at the best models to build some intution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e1d72b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(model.cv_results_)\n",
    "scoresCV = scores[['params','mean_test_score','std_test_score','mean_train_score']].sort_values(by = 'mean_test_score', \\\n",
    "                                                    ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b5f0c034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'max_depth': 15, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 100}</td>\n",
       "      <td>0.900448</td>\n",
       "      <td>0.005080</td>\n",
       "      <td>0.988740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{'max_depth': 25, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 100}</td>\n",
       "      <td>0.899552</td>\n",
       "      <td>0.003860</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'max_depth': 20, 'max_features': 8, 'min_impurity_decrease': 0.0, 'n_estimators': 200}</td>\n",
       "      <td>0.899040</td>\n",
       "      <td>0.005188</td>\n",
       "      <td>0.999104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'max_depth': 25, 'max_features': 8, 'min_impurity_decrease': 0.0, 'n_estimators': 200}</td>\n",
       "      <td>0.898912</td>\n",
       "      <td>0.006002</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 15, 'max_features': None, 'min_impurity_decrease': 0.0, 'n_estimators': 50}</td>\n",
       "      <td>0.898273</td>\n",
       "      <td>0.006855</td>\n",
       "      <td>0.989028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'max_depth': 15, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 200}</td>\n",
       "      <td>0.898145</td>\n",
       "      <td>0.005480</td>\n",
       "      <td>0.988100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{'max_depth': 25, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 150}</td>\n",
       "      <td>0.898017</td>\n",
       "      <td>0.004294</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'max_depth': 25, 'max_features': 8, 'min_impurity_decrease': 0.0, 'n_estimators': 100}</td>\n",
       "      <td>0.898017</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>{'max_depth': 25, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 200}</td>\n",
       "      <td>0.898017</td>\n",
       "      <td>0.005223</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'max_depth': 20, 'max_features': 8, 'min_impurity_decrease': 0.0, 'n_estimators': 100}</td>\n",
       "      <td>0.897889</td>\n",
       "      <td>0.005674</td>\n",
       "      <td>0.999104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'max_depth': 15, 'max_features': 8, 'min_impurity_decrease': 0.0, 'n_estimators': 200}</td>\n",
       "      <td>0.897889</td>\n",
       "      <td>0.003766</td>\n",
       "      <td>0.989187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'max_depth': 25, 'max_features': None, 'min_impurity_decrease': 0.0, 'n_estimators': 150}</td>\n",
       "      <td>0.897889</td>\n",
       "      <td>0.005844</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'max_depth': 20, 'max_features': 8, 'min_impurity_decrease': 0.0, 'n_estimators': 150}</td>\n",
       "      <td>0.897761</td>\n",
       "      <td>0.004193</td>\n",
       "      <td>0.999136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'max_depth': 15, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 150}</td>\n",
       "      <td>0.897761</td>\n",
       "      <td>0.005627</td>\n",
       "      <td>0.988388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'max_depth': 20, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 200}</td>\n",
       "      <td>0.897633</td>\n",
       "      <td>0.003817</td>\n",
       "      <td>0.999072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'max_depth': 20, 'max_features': None, 'min_impurity_decrease': 0.0, 'n_estimators': 200}</td>\n",
       "      <td>0.897633</td>\n",
       "      <td>0.006587</td>\n",
       "      <td>0.999264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'max_depth': 15, 'max_features': 8, 'min_impurity_decrease': 0.0, 'n_estimators': 150}</td>\n",
       "      <td>0.897505</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.989379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'max_depth': 20, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 150}</td>\n",
       "      <td>0.897505</td>\n",
       "      <td>0.006075</td>\n",
       "      <td>0.999040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'max_depth': 20, 'max_features': 8, 'min_impurity_decrease': 0.0, 'n_estimators': 50}</td>\n",
       "      <td>0.897505</td>\n",
       "      <td>0.006235</td>\n",
       "      <td>0.998848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 15, 'max_features': None, 'min_impurity_decrease': 0.0, 'n_estimators': 200}</td>\n",
       "      <td>0.897377</td>\n",
       "      <td>0.005731</td>\n",
       "      <td>0.989123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 15, 'max_features': 8, 'min_impurity_decrease': 0.0, 'n_estimators': 100}</td>\n",
       "      <td>0.897121</td>\n",
       "      <td>0.005157</td>\n",
       "      <td>0.988580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'max_depth': 20, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 50}</td>\n",
       "      <td>0.897121</td>\n",
       "      <td>0.004929</td>\n",
       "      <td>0.998369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'max_depth': 25, 'max_features': 8, 'min_impurity_decrease': 0.0, 'n_estimators': 150}</td>\n",
       "      <td>0.896993</td>\n",
       "      <td>0.006710</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'max_depth': 20, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 100}</td>\n",
       "      <td>0.896865</td>\n",
       "      <td>0.005799</td>\n",
       "      <td>0.998912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'max_depth': 25, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 50}</td>\n",
       "      <td>0.896865</td>\n",
       "      <td>0.004458</td>\n",
       "      <td>0.999616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 15, 'max_features': 8, 'min_impurity_decrease': 0.0, 'n_estimators': 50}</td>\n",
       "      <td>0.896865</td>\n",
       "      <td>0.005613</td>\n",
       "      <td>0.987748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'max_depth': 15, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 50}</td>\n",
       "      <td>0.896481</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.987684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'max_depth': 20, 'max_features': None, 'min_impurity_decrease': 0.0, 'n_estimators': 150}</td>\n",
       "      <td>0.896481</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>0.999200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'max_depth': 25, 'max_features': None, 'min_impurity_decrease': 0.0, 'n_estimators': 200}</td>\n",
       "      <td>0.896353</td>\n",
       "      <td>0.006950</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'max_depth': 20, 'max_features': None, 'min_impurity_decrease': 0.0, 'n_estimators': 100}</td>\n",
       "      <td>0.896353</td>\n",
       "      <td>0.007857</td>\n",
       "      <td>0.998880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'max_depth': 25, 'max_features': None, 'min_impurity_decrease': 0.0, 'n_estimators': 100}</td>\n",
       "      <td>0.896097</td>\n",
       "      <td>0.006118</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 15, 'max_features': None, 'min_impurity_decrease': 0.0, 'n_estimators': 150}</td>\n",
       "      <td>0.896097</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>0.989347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'max_depth': 25, 'max_features': 8, 'min_impurity_decrease': 0.0, 'n_estimators': 50}</td>\n",
       "      <td>0.895841</td>\n",
       "      <td>0.005267</td>\n",
       "      <td>0.999744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 15, 'max_features': None, 'min_impurity_decrease': 0.0, 'n_estimators': 100}</td>\n",
       "      <td>0.895329</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>0.988868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'max_depth': 25, 'max_features': None, 'min_impurity_decrease': 0.0, 'n_estimators': 50}</td>\n",
       "      <td>0.895074</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.999648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'max_depth': 20, 'max_features': None, 'min_impurity_decrease': 0.0, 'n_estimators': 50}</td>\n",
       "      <td>0.894050</td>\n",
       "      <td>0.006024</td>\n",
       "      <td>0.998401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        params  \\\n",
       "9      {'max_depth': 15, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 100}   \n",
       "33     {'max_depth': 25, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 100}   \n",
       "19     {'max_depth': 20, 'max_features': 8, 'min_impurity_decrease': 0.0, 'n_estimators': 200}   \n",
       "31     {'max_depth': 25, 'max_features': 8, 'min_impurity_decrease': 0.0, 'n_estimators': 200}   \n",
       "0    {'max_depth': 15, 'max_features': None, 'min_impurity_decrease': 0.0, 'n_estimators': 50}   \n",
       "11     {'max_depth': 15, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 200}   \n",
       "34     {'max_depth': 25, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 150}   \n",
       "29     {'max_depth': 25, 'max_features': 8, 'min_impurity_decrease': 0.0, 'n_estimators': 100}   \n",
       "35     {'max_depth': 25, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 200}   \n",
       "17     {'max_depth': 20, 'max_features': 8, 'min_impurity_decrease': 0.0, 'n_estimators': 100}   \n",
       "7      {'max_depth': 15, 'max_features': 8, 'min_impurity_decrease': 0.0, 'n_estimators': 200}   \n",
       "26  {'max_depth': 25, 'max_features': None, 'min_impurity_decrease': 0.0, 'n_estimators': 150}   \n",
       "18     {'max_depth': 20, 'max_features': 8, 'min_impurity_decrease': 0.0, 'n_estimators': 150}   \n",
       "10     {'max_depth': 15, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 150}   \n",
       "23     {'max_depth': 20, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 200}   \n",
       "15  {'max_depth': 20, 'max_features': None, 'min_impurity_decrease': 0.0, 'n_estimators': 200}   \n",
       "6      {'max_depth': 15, 'max_features': 8, 'min_impurity_decrease': 0.0, 'n_estimators': 150}   \n",
       "22     {'max_depth': 20, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 150}   \n",
       "16      {'max_depth': 20, 'max_features': 8, 'min_impurity_decrease': 0.0, 'n_estimators': 50}   \n",
       "3   {'max_depth': 15, 'max_features': None, 'min_impurity_decrease': 0.0, 'n_estimators': 200}   \n",
       "5      {'max_depth': 15, 'max_features': 8, 'min_impurity_decrease': 0.0, 'n_estimators': 100}   \n",
       "20      {'max_depth': 20, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 50}   \n",
       "30     {'max_depth': 25, 'max_features': 8, 'min_impurity_decrease': 0.0, 'n_estimators': 150}   \n",
       "21     {'max_depth': 20, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 100}   \n",
       "32      {'max_depth': 25, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 50}   \n",
       "4       {'max_depth': 15, 'max_features': 8, 'min_impurity_decrease': 0.0, 'n_estimators': 50}   \n",
       "8       {'max_depth': 15, 'max_features': 4, 'min_impurity_decrease': 0.0, 'n_estimators': 50}   \n",
       "14  {'max_depth': 20, 'max_features': None, 'min_impurity_decrease': 0.0, 'n_estimators': 150}   \n",
       "27  {'max_depth': 25, 'max_features': None, 'min_impurity_decrease': 0.0, 'n_estimators': 200}   \n",
       "13  {'max_depth': 20, 'max_features': None, 'min_impurity_decrease': 0.0, 'n_estimators': 100}   \n",
       "25  {'max_depth': 25, 'max_features': None, 'min_impurity_decrease': 0.0, 'n_estimators': 100}   \n",
       "2   {'max_depth': 15, 'max_features': None, 'min_impurity_decrease': 0.0, 'n_estimators': 150}   \n",
       "28      {'max_depth': 25, 'max_features': 8, 'min_impurity_decrease': 0.0, 'n_estimators': 50}   \n",
       "1   {'max_depth': 15, 'max_features': None, 'min_impurity_decrease': 0.0, 'n_estimators': 100}   \n",
       "24   {'max_depth': 25, 'max_features': None, 'min_impurity_decrease': 0.0, 'n_estimators': 50}   \n",
       "12   {'max_depth': 20, 'max_features': None, 'min_impurity_decrease': 0.0, 'n_estimators': 50}   \n",
       "\n",
       "    mean_test_score  std_test_score  mean_train_score  \n",
       "9          0.900448        0.005080          0.988740  \n",
       "33         0.899552        0.003860          1.000000  \n",
       "19         0.899040        0.005188          0.999104  \n",
       "31         0.898912        0.006002          1.000000  \n",
       "0          0.898273        0.006855          0.989028  \n",
       "11         0.898145        0.005480          0.988100  \n",
       "34         0.898017        0.004294          1.000000  \n",
       "29         0.898017        0.006145          1.000000  \n",
       "35         0.898017        0.005223          1.000000  \n",
       "17         0.897889        0.005674          0.999104  \n",
       "7          0.897889        0.003766          0.989187  \n",
       "26         0.897889        0.005844          1.000000  \n",
       "18         0.897761        0.004193          0.999136  \n",
       "10         0.897761        0.005627          0.988388  \n",
       "23         0.897633        0.003817          0.999072  \n",
       "15         0.897633        0.006587          0.999264  \n",
       "6          0.897505        0.004055          0.989379  \n",
       "22         0.897505        0.006075          0.999040  \n",
       "16         0.897505        0.006235          0.998848  \n",
       "3          0.897377        0.005731          0.989123  \n",
       "5          0.897121        0.005157          0.988580  \n",
       "20         0.897121        0.004929          0.998369  \n",
       "30         0.896993        0.006710          1.000000  \n",
       "21         0.896865        0.005799          0.998912  \n",
       "32         0.896865        0.004458          0.999616  \n",
       "4          0.896865        0.005613          0.987748  \n",
       "8          0.896481        0.005172          0.987684  \n",
       "14         0.896481        0.005757          0.999200  \n",
       "27         0.896353        0.006950          1.000000  \n",
       "13         0.896353        0.007857          0.998880  \n",
       "25         0.896097        0.006118          1.000000  \n",
       "2          0.896097        0.006145          0.989347  \n",
       "28         0.895841        0.005267          0.999744  \n",
       "1          0.895329        0.006557          0.988868  \n",
       "24         0.895074        0.005679          0.999648  \n",
       "12         0.894050        0.006024          0.998401  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoresCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cb610a",
   "metadata": {},
   "source": [
    "Q: what parameters seem to be consistently important for the top models? And which ones are not important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4829cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fa990a",
   "metadata": {},
   "source": [
    "For comparison, this is how to set up a Randomized Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "251b0bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best params, best score: 0.8962 {'n_estimators': 100, 'min_impurity_decrease': 0.0, 'max_features': 4, 'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'min_impurity_decrease':[0.5, 0.2, 0.0], \\\n",
    "              'max_features':[None,4,2], 'n_estimators':[10, 50, 100], 'max_depth': [5,10]}\n",
    "\n",
    "model = RandomizedSearchCV(RandomForestClassifier(), parameters, cv = KFold(n_splits=5, shuffle=True), \\\n",
    "                     verbose = 2, n_jobs = -1, return_train_score=True, n_iter = 30)\n",
    "model.fit(seldf,target)\n",
    "\n",
    "print('Best params, best score:', \"{:.4f}\".format(model.best_score_), \\\n",
    "      model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e7dc8d",
   "metadata": {},
   "source": [
    "#### Q: What is the most convenient strategy here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d516b66f",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fda080",
   "metadata": {},
   "source": [
    "Medium article explaining XGBoost: [here](https://towardsdatascience.com/a-beginners-guide-to-xgboost-87f5d4c30ed7); some nice tutorials from XGBoost's site: [here](https://xgboost.readthedocs.io/en/latest/tutorials/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f450a3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2c26f562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary:logistic',\n",
       " 'use_label_encoder': None,\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'callbacks': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'early_stopping_rounds': None,\n",
       " 'enable_categorical': False,\n",
       " 'eval_metric': None,\n",
       " 'feature_types': None,\n",
       " 'gamma': None,\n",
       " 'gpu_id': None,\n",
       " 'grow_policy': None,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_bin': None,\n",
       " 'max_cat_threshold': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': None,\n",
       " 'max_leaves': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'predictor': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'sampling_method': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3142258",
   "metadata": {},
   "source": [
    "This is one possible grid (note - this takes a few minutes on my machine)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a4a7478d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=10, max_features=2, min_impurity_decrease=0.5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.0, n_estimators=50; total time=   2.7s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.0, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.0, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.0, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=2, min_impurity_decrease=0.0, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=10, max_features=2, min_impurity_decrease=0.0, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.5, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.5, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.5, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.0, n_estimators=10; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.5, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.5, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.0, n_estimators=10; total time=   0.5s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.5, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.2, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.0, n_estimators=10; total time=   0.5s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.0, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.0, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.2, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.2, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=2, min_impurity_decrease=0.5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.0, n_estimators=50; total time=   2.7s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.0, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.0, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.0, n_estimators=100; total time=   3.1s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.0, n_estimators=100; total time=   3.1s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.0, n_estimators=100; total time=   3.1s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.0, n_estimators=100; total time=   3.1s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.0, n_estimators=100; total time=   3.1s\n",
      "[CV] END max_depth=10, max_features=2, min_impurity_decrease=0.5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.0, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=2, min_impurity_decrease=0.0, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.0, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.0, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.5, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.5, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.5, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.5, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=2, min_impurity_decrease=0.2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.0, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.0, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.5, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.5, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=2, min_impurity_decrease=0.5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.0, n_estimators=50; total time=   2.7s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.0, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.0, n_estimators=10; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.5, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.5, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.0, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.0, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=2, min_impurity_decrease=0.0, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.0, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.0, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.0, n_estimators=10; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.0, n_estimators=10; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.0, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.0, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.0, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.0, n_estimators=50; total time=   2.7s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.0, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.0, n_estimators=50; total time=   2.7s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.0, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=2, min_impurity_decrease=0.2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.0, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.5, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.5, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.2, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=2, min_impurity_decrease=0.2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.0, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.0, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.0, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=None, min_impurity_decrease=0.0, n_estimators=10; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.5, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.5, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.5, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=5, max_features=2, min_impurity_decrease=0.2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.0, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=2, min_impurity_decrease=0.0, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.5, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=2, min_impurity_decrease=0.2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.0, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.0, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=4, min_impurity_decrease=0.5, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.0, n_estimators=10; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.0, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.0, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, max_features=2, min_impurity_decrease=0.5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=2, min_impurity_decrease=0.2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.0, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.0, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.0, n_estimators=10; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=None, min_impurity_decrease=0.0, n_estimators=10; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.0, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=4, min_impurity_decrease=0.0, n_estimators=100; total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/vwetzell/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params, best score: 0.7085 {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'max_depth': [5,10], 'n_estimators':[10, 50,100], \n",
    "              'learning_rate': [0.05, 0.1, 0.2], 'subsample':[0.5,1]}\n",
    "\n",
    "model = GridSearchCV(xgb.XGBRegressor(), parameters, cv = KFold(n_splits=5, shuffle=True), \\\n",
    "                     verbose = 2, n_jobs = 4, return_train_score=True)\n",
    "\n",
    "model.fit(seldf,target)\n",
    "\n",
    "print('Best params, best score:', \"{:.4f}\".format(model.best_score_), \\\n",
    "      model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f912cee0",
   "metadata": {},
   "source": [
    "### Task: \n",
    "\n",
    "### Try to improve on our current scores, by further optimizing a RF or XGB, and/or by engineering new features that could be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08d4194",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a07b90e",
   "metadata": {},
   "source": [
    "Tree-based methods have a built-in feature importance method. It is important that the estimator has been \"fit\" before you can access the feature importances. If you are using this just to build an understanding of which features most participate to a prediction (and not to assess the performance of a model with a given set of features), you can use the full learning set.\n",
    "\n",
    "Note:\n",
    "\n",
    "The ranking (more in general, the information gain associated to each feature) is algorithm-dependent and often affected by correlations among variables. I would encourage you to think about it as an indication, and/or to derive it for a few different algorithms to increase robustness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2c2b6ea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    in...\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=None, ...),\n",
       "             n_jobs=4,\n",
       "             param_grid={'learning_rate': [0.05, 0.1, 0.2],\n",
       "                         'max_depth': [5, 10], 'n_estimators': [10, 50, 100],\n",
       "                         'subsample': [0.5, 1]},\n",
       "             return_train_score=True, verbose=2)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6a00902c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=10, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=10, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=50, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=10, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=50, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=50, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=10, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=50, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=10, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.2s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=10, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=10, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=10, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=10, subsample=1; total time=   0.1s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=50, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=50, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=50, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=50, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=50, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=50, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=50, subsample=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.2, max_depth=5, n_estimators=10, subsample=1; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    in...\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=None, ...),\n",
       "             n_jobs=4,\n",
       "             param_grid={'learning_rate': [0.05, 0.1, 0.2],\n",
       "                         'max_depth': [5, 10], 'n_estimators': [10, 50, 100],\n",
       "                         'subsample': [0.5, 1]},\n",
       "             return_train_score=True, verbose=2)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(seldf, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "488ff01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03627539, 0.04845478, 0.03815196, 0.03899358, 0.07467259,\n",
       "       0.0644984 , 0.12308981, 0.1090676 , 0.05226038, 0.04541136,\n",
       "       0.03640574, 0.04084725, 0.13724393, 0.08711147, 0.06751577],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(learning_rate=0.05,max_depth=10,n_estimators=100,subsample=0.5)\n",
    "\n",
    "model.fit(seldf,target)\n",
    "\n",
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f904046a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature: r-i, 12 (0.137244)\n",
      "2. feature: u-r, 6 (0.123090)\n",
      "3. feature: u-i, 7 (0.109068)\n",
      "4. feature: r-z, 13 (0.087111)\n",
      "5. feature: z, 4 (0.074673)\n",
      "6. feature: i-z, 14 (0.067516)\n",
      "7. feature: u-g, 5 (0.064498)\n",
      "8. feature: u-z, 8 (0.052260)\n",
      "9. feature: g, 1 (0.048455)\n",
      "10. feature: g-r, 9 (0.045411)\n",
      "11. feature: g-z, 11 (0.040847)\n",
      "12. feature: i, 3 (0.038994)\n",
      "13. feature: r, 2 (0.038152)\n",
      "14. feature: g-i, 10 (0.036406)\n",
      "15. feature: u, 0 (0.036275)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = model.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(seldf.shape[1]):\n",
    "    print(\"%d. feature: %s, %d (%f)\" % (f + 1, seldf.columns[indices[f]], indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(seldf.shape[1]), importances[indices],\n",
    "       color=\"r\", align=\"center\")\n",
    "plt.xticks(range(seldf.shape[1]), seldf.columns[indices])\n",
    "plt.xlim([-1, seldf.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "78caa726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>u-g</th>\n",
       "      <th>u-r</th>\n",
       "      <th>u-i</th>\n",
       "      <th>u-z</th>\n",
       "      <th>g-r</th>\n",
       "      <th>g-i</th>\n",
       "      <th>g-z</th>\n",
       "      <th>r-i</th>\n",
       "      <th>r-z</th>\n",
       "      <th>i-z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.56366</td>\n",
       "      <td>22.30574</td>\n",
       "      <td>20.71001</td>\n",
       "      <td>19.60254</td>\n",
       "      <td>19.29095</td>\n",
       "      <td>0.25792</td>\n",
       "      <td>1.85365</td>\n",
       "      <td>2.96112</td>\n",
       "      <td>3.27271</td>\n",
       "      <td>1.59573</td>\n",
       "      <td>2.70320</td>\n",
       "      <td>3.01479</td>\n",
       "      <td>1.10747</td>\n",
       "      <td>1.41906</td>\n",
       "      <td>0.31159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.17278</td>\n",
       "      <td>17.70152</td>\n",
       "      <td>16.99073</td>\n",
       "      <td>16.57557</td>\n",
       "      <td>16.32981</td>\n",
       "      <td>1.47126</td>\n",
       "      <td>2.18205</td>\n",
       "      <td>2.59721</td>\n",
       "      <td>2.84297</td>\n",
       "      <td>0.71079</td>\n",
       "      <td>1.12595</td>\n",
       "      <td>1.37171</td>\n",
       "      <td>0.41516</td>\n",
       "      <td>0.66092</td>\n",
       "      <td>0.24576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.46931</td>\n",
       "      <td>20.59701</td>\n",
       "      <td>18.95319</td>\n",
       "      <td>18.31693</td>\n",
       "      <td>17.91509</td>\n",
       "      <td>5.87230</td>\n",
       "      <td>7.51612</td>\n",
       "      <td>8.15238</td>\n",
       "      <td>8.55422</td>\n",
       "      <td>1.64382</td>\n",
       "      <td>2.28008</td>\n",
       "      <td>2.68192</td>\n",
       "      <td>0.63626</td>\n",
       "      <td>1.03810</td>\n",
       "      <td>0.40184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.97774</td>\n",
       "      <td>21.37690</td>\n",
       "      <td>21.13597</td>\n",
       "      <td>21.08800</td>\n",
       "      <td>20.68579</td>\n",
       "      <td>0.60084</td>\n",
       "      <td>0.84177</td>\n",
       "      <td>0.88974</td>\n",
       "      <td>1.29195</td>\n",
       "      <td>0.24093</td>\n",
       "      <td>0.28890</td>\n",
       "      <td>0.69111</td>\n",
       "      <td>0.04797</td>\n",
       "      <td>0.45018</td>\n",
       "      <td>0.40221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.10911</td>\n",
       "      <td>17.95012</td>\n",
       "      <td>17.06489</td>\n",
       "      <td>16.71905</td>\n",
       "      <td>16.52725</td>\n",
       "      <td>2.15899</td>\n",
       "      <td>3.04422</td>\n",
       "      <td>3.39006</td>\n",
       "      <td>3.58186</td>\n",
       "      <td>0.88523</td>\n",
       "      <td>1.23107</td>\n",
       "      <td>1.42287</td>\n",
       "      <td>0.34584</td>\n",
       "      <td>0.53764</td>\n",
       "      <td>0.19180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>19.88653</td>\n",
       "      <td>17.94380</td>\n",
       "      <td>16.66097</td>\n",
       "      <td>16.15675</td>\n",
       "      <td>15.83632</td>\n",
       "      <td>1.94273</td>\n",
       "      <td>3.22556</td>\n",
       "      <td>3.72978</td>\n",
       "      <td>4.05021</td>\n",
       "      <td>1.28283</td>\n",
       "      <td>1.78705</td>\n",
       "      <td>2.10748</td>\n",
       "      <td>0.50422</td>\n",
       "      <td>0.82465</td>\n",
       "      <td>0.32043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>18.23540</td>\n",
       "      <td>16.83241</td>\n",
       "      <td>16.33695</td>\n",
       "      <td>16.16904</td>\n",
       "      <td>16.09191</td>\n",
       "      <td>1.40299</td>\n",
       "      <td>1.89845</td>\n",
       "      <td>2.06636</td>\n",
       "      <td>2.14349</td>\n",
       "      <td>0.49546</td>\n",
       "      <td>0.66337</td>\n",
       "      <td>0.74050</td>\n",
       "      <td>0.16791</td>\n",
       "      <td>0.24504</td>\n",
       "      <td>0.07713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>16.05739</td>\n",
       "      <td>14.82542</td>\n",
       "      <td>14.27171</td>\n",
       "      <td>13.96027</td>\n",
       "      <td>13.73334</td>\n",
       "      <td>1.23197</td>\n",
       "      <td>1.78568</td>\n",
       "      <td>2.09712</td>\n",
       "      <td>2.32405</td>\n",
       "      <td>0.55371</td>\n",
       "      <td>0.86515</td>\n",
       "      <td>1.09208</td>\n",
       "      <td>0.31144</td>\n",
       "      <td>0.53837</td>\n",
       "      <td>0.22693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>21.20886</td>\n",
       "      <td>19.46307</td>\n",
       "      <td>19.10678</td>\n",
       "      <td>18.82092</td>\n",
       "      <td>18.78040</td>\n",
       "      <td>1.74579</td>\n",
       "      <td>2.10208</td>\n",
       "      <td>2.38794</td>\n",
       "      <td>2.42846</td>\n",
       "      <td>0.35629</td>\n",
       "      <td>0.64215</td>\n",
       "      <td>0.68267</td>\n",
       "      <td>0.28586</td>\n",
       "      <td>0.32638</td>\n",
       "      <td>0.04052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>19.12313</td>\n",
       "      <td>17.36222</td>\n",
       "      <td>16.41801</td>\n",
       "      <td>15.96346</td>\n",
       "      <td>15.63152</td>\n",
       "      <td>1.76091</td>\n",
       "      <td>2.70512</td>\n",
       "      <td>3.15967</td>\n",
       "      <td>3.49161</td>\n",
       "      <td>0.94421</td>\n",
       "      <td>1.39876</td>\n",
       "      <td>1.73070</td>\n",
       "      <td>0.45455</td>\n",
       "      <td>0.78649</td>\n",
       "      <td>0.33194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7815 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             u         g         r         i         z      u-g      u-r  \\\n",
       "0     22.56366  22.30574  20.71001  19.60254  19.29095  0.25792  1.85365   \n",
       "3     19.17278  17.70152  16.99073  16.57557  16.32981  1.47126  2.18205   \n",
       "4     26.46931  20.59701  18.95319  18.31693  17.91509  5.87230  7.51612   \n",
       "5     21.97774  21.37690  21.13597  21.08800  20.68579  0.60084  0.84177   \n",
       "7     20.10911  17.95012  17.06489  16.71905  16.52725  2.15899  3.04422   \n",
       "...        ...       ...       ...       ...       ...      ...      ...   \n",
       "9995  19.88653  17.94380  16.66097  16.15675  15.83632  1.94273  3.22556   \n",
       "9996  18.23540  16.83241  16.33695  16.16904  16.09191  1.40299  1.89845   \n",
       "9997  16.05739  14.82542  14.27171  13.96027  13.73334  1.23197  1.78568   \n",
       "9998  21.20886  19.46307  19.10678  18.82092  18.78040  1.74579  2.10208   \n",
       "9999  19.12313  17.36222  16.41801  15.96346  15.63152  1.76091  2.70512   \n",
       "\n",
       "          u-i      u-z      g-r      g-i      g-z      r-i      r-z      i-z  \n",
       "0     2.96112  3.27271  1.59573  2.70320  3.01479  1.10747  1.41906  0.31159  \n",
       "3     2.59721  2.84297  0.71079  1.12595  1.37171  0.41516  0.66092  0.24576  \n",
       "4     8.15238  8.55422  1.64382  2.28008  2.68192  0.63626  1.03810  0.40184  \n",
       "5     0.88974  1.29195  0.24093  0.28890  0.69111  0.04797  0.45018  0.40221  \n",
       "7     3.39006  3.58186  0.88523  1.23107  1.42287  0.34584  0.53764  0.19180  \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...  \n",
       "9995  3.72978  4.05021  1.28283  1.78705  2.10748  0.50422  0.82465  0.32043  \n",
       "9996  2.06636  2.14349  0.49546  0.66337  0.74050  0.16791  0.24504  0.07713  \n",
       "9997  2.09712  2.32405  0.55371  0.86515  1.09208  0.31144  0.53837  0.22693  \n",
       "9998  2.38794  2.42846  0.35629  0.64215  0.68267  0.28586  0.32638  0.04052  \n",
       "9999  3.15967  3.49161  0.94421  1.39876  1.73070  0.45455  0.78649  0.33194  \n",
       "\n",
       "[7815 rows x 15 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad76ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb261335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
